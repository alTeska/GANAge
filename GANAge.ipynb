{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python main.py --use_labels=False --use_reconst_loss=True\n",
    "import os\n",
    "from solver import Solver\n",
    "from torch.backends import cudnn\n",
    "from data_loader import get_loader\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "cudnn.benchmark = True \n",
    " \n",
    "config1 = {\n",
    "'image_size' : 200, \n",
    "'g_conv_dim' : 64, \n",
    "'d_conv_dim' : 64, \n",
    "'num_classes' : 10, \n",
    "'train_iters' : 40000,\n",
    "'batch_size' : 4,\n",
    "'num_workers' : 2,\n",
    "'lr' : 0.0002,\n",
    "'beta1' : 0.5,\n",
    "'beta2' : 0.999,\n",
    "\n",
    "'mode'  :'train',\n",
    "'model_path' :'./models',\n",
    "'sample_path' :'./samples',\n",
    "'mnist_path' :'./mnist',\n",
    "'svhn_path' :'./svhn',\n",
    "'log_step' : 10,\n",
    "'sample_step' : 500,\n",
    "\n",
    "'use_labels': False, \n",
    "'use_reconst_loss' : True, \n",
    "}\n",
    "\n",
    "config = dotdict(config1)\n",
    "old_loader, young_loader = get_loader(config)\n",
    "\n",
    "solver = Solver(config, old_loader, young_loader)\n",
    "solver.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.backends import cudnn\n",
    "from data_loader import get_loader\n",
    "from data_utils import FaceData\n",
    "from model import G12, G21\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "cudnn.benchmark = True \n",
    " \n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "config1 = {\n",
    "'image_size' : 200, \n",
    "'g_conv_dim' : 64, \n",
    "'d_conv_dim' : 64, \n",
    "'num_classes' : 10, \n",
    "'train_iters' : 40000,\n",
    "'batch_size' : 4,\n",
    "'num_workers' : 2,\n",
    "'lr' : 0.0002,\n",
    "'beta1' : 0.5,\n",
    "'beta2' : 0.999,\n",
    "\n",
    "'mode'  :'train',\n",
    "'model_path' :'./models',\n",
    "'sample_path' :'./samples',\n",
    "'mnist_path' :'./mnist',\n",
    "'svhn_path' :'./svhn',\n",
    "'log_step' : 10,\n",
    "'sample_step' : 500,\n",
    "\n",
    "'use_labels': False, \n",
    "'use_reconst_loss' : True, \n",
    "}\n",
    "\n",
    "config = dotdict(config1)\n",
    "\n",
    "old = FaceData(image_paths_file='LAG/train/train.txt', young=False)\n",
    "young = FaceData(image_paths_file='LAG/train/train.txt')\n",
    "\n",
    "g12 = G12(conv_dim=config.g_conv_dim)\n",
    "state_G12 = torch.load('models/g12-36000.pkl')\n",
    "g12.load_state_dict(state_G12)\n",
    "\n",
    "g21 = G21(conv_dim=config.g_conv_dim)\n",
    "state_G21 = torch.load('models/g21-36000.pkl')\n",
    "g21.load_state_dict(state_G21)\n",
    "\n",
    "\n",
    "num_example_imgs = 3\n",
    "plt.switch_backend('agg')\n",
    "plt.ion()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "#for i, (img, img_label) in enumerate(young[-num_example_imgs:]):\n",
    "\n",
    "img, _ = young[-1]\n",
    "inputs = img.unsqueeze(0)\n",
    "inputs = Variable(inputs)\n",
    "    \n",
    "outputs = g12.forward(inputs)\n",
    "reverse = g21.forward(outputs)    \n",
    "    \n",
    "pred = outputs.data.cpu()\n",
    "rev = reverse.data.cpu()\n",
    "\n",
    "#pred = pred.type(torch.LongTensor)    \n",
    "img, pred = img.numpy(), pred.numpy()\n",
    "rev = rev.numpy()\n",
    "pred = np.around(pred,decimals=2)\n",
    "pred = pred - np.min(pred)\n",
    "print((pred - np.min(pred)))\n",
    "\n",
    "rev = np.around(rev,decimals=2)\n",
    "rev = rev - np.min(rev)\n",
    "\n",
    "# img\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "print(img.transpose(1,2,0).shape)\n",
    "plt.imshow(img.transpose(1,2,0))\n",
    "    \n",
    "# pred\n",
    "plt.subplot(1, 2 ,2)\n",
    "plt.axis('off')\n",
    "#plt.imshow(pred.reshape(200,200,3))\n",
    "plt.imshow(rev.reshape(200,200,3))\n",
    "        \n",
    "plt.savefig('randomfig.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num must be 1 <= num <= 9, not 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24ea5291a0ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;31m# img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_example_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ateska/anaconda3/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ateska/anaconda3/lib/python3.5/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1072\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ateska/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m                     raise ValueError(\n\u001b[0;32m     63\u001b[0m                         \"num must be 1 <= num <= {maxn}, not {num}\".format(\n\u001b[1;32m---> 64\u001b[1;33m                             maxn=rows*cols, num=num))\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subplotspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[1;31m# num - 1 for converting from MATLAB to python indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: num must be 1 <= num <= 9, not 10"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.backends import cudnn\n",
    "from data_loader import get_loader\n",
    "from data_utils import FaceData\n",
    "from model import G12, G21, D1, D2\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cudnn.benchmark = True \n",
    "\n",
    "def merge_images(sources, targets, batch_size=9, k=10):\n",
    "    _, h, w = sources.shape\n",
    "    row = int(np.sqrt(batch_size))\n",
    "    merged = np.zeros([3, row*h, row*w*2])\n",
    "    for idx, (s, t) in enumerate(zip(sources, targets)):\n",
    "        i = idx // row\n",
    "        j = idx % row\n",
    "        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
    "        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
    "    return merged.transpose(1, 2, 0)\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "config1 = {\n",
    "'image_size' : 200, \n",
    "'g_conv_dim' : 64, \n",
    "'d_conv_dim' : 64, \n",
    "'num_classes' : 10, \n",
    "'train_iters' : 40000,\n",
    "'batch_size' : 9,\n",
    "'num_workers' : 2,\n",
    "'lr' : 0.0002,\n",
    "'beta1' : 0.5,\n",
    "'beta2' : 0.999,\n",
    "\n",
    "'mode'  :'train',\n",
    "'model_path' :'./models',\n",
    "'sample_path' :'./samples',\n",
    "'mnist_path' :'./mnist',\n",
    "'svhn_path' :'./svhn',\n",
    "'log_step' : 10,\n",
    "'sample_step' : 500,\n",
    "\n",
    "'use_labels': False, \n",
    "'use_reconst_loss' : True, \n",
    "}\n",
    "\n",
    "config = dotdict(config1)\n",
    "\n",
    "#loading data\n",
    "old = FaceData(image_paths_file='LAG/train/train.txt', young=False)\n",
    "young = FaceData(image_paths_file='LAG/train/train.txt')\n",
    "\n",
    "#loading models\n",
    "g12 = G12(conv_dim=config.g_conv_dim)\n",
    "state_G12 = torch.load('models/g12-36000.pkl')\n",
    "g12.load_state_dict(state_G12)\n",
    "\n",
    "d1 = D1(conv_dim=config.g_conv_dim)\n",
    "state_D1 = torch.load('models/d1-36000.pkl')\n",
    "d1.load_state_dict(state_D1)\n",
    "\n",
    "g21 = G21(conv_dim=config.g_conv_dim)\n",
    "state_G21 = torch.load('models/g21-36000.pkl')\n",
    "g21.load_state_dict(state_G21)\n",
    "\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "plt.ion()\n",
    "\n",
    "#plt.figure(figsize=(15,5))\n",
    "plt.figure()\n",
    "\n",
    "num_example_imgs = 3\n",
    "#for i, (img, img_label) in enumerate(young[-(num_example_imgs):]):\n",
    "for i, (img, img_label) in enumerate(young[-(num_example_imgs+100):]):\n",
    "\n",
    "    inputs = img.unsqueeze(0)\n",
    "    inputs = Variable(inputs)\n",
    "    \n",
    "    outputs = g12(inputs)\n",
    "    d1_out = d1(outputs)\n",
    "    #print(d1_out)\n",
    "    reverse = g21(outputs)    \n",
    "    \n",
    "    pred = outputs[0].data.cpu()\n",
    "    rev = reverse[0].data.cpu()\n",
    "    \n",
    "    img, pred, rev = img.numpy(), pred.numpy(), rev.numpy() \n",
    "\n",
    "    #pred = np.around(pred,decimals=2)\n",
    "    #pred = (pred - np.min(pred))*255/np.max(pred)\n",
    "    #rev = np.around(rev,decimals=2)\n",
    "    #rev = rev - np.min(rev)\n",
    "\n",
    "    #merged = merge_images(pred, rev)\n",
    "\n",
    "    # img\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.transpose(1,2,0))\n",
    "    \n",
    "    # pred\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 2)\n",
    "    plt.axis('off')\n",
    "    #plt.imshow(merged)\n",
    "    plt.imshow(pred.reshape(200,200,3))\n",
    "    \n",
    "    # rev\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(rev.reshape(200,200,3))\n",
    "    \n",
    "    plt.savefig('randomfig.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
