{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python main.py --use_labels=False --use_reconst_loss=True\n",
    "import os\n",
    "from solver import Solver\n",
    "from torch.backends import cudnn\n",
    "from data_loader import get_loader\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "cudnn.benchmark = True \n",
    " \n",
    "config1 = {\n",
    "'image_size' : 200, \n",
    "'g_conv_dim' : 64, \n",
    "'d_conv_dim' : 64, \n",
    "'num_classes' : 10, \n",
    "'train_iters' : 40000,\n",
    "'batch_size' : 4,\n",
    "'num_workers' : 2,\n",
    "'lr' : 0.0002,\n",
    "'beta1' : 0.5,\n",
    "'beta2' : 0.999,\n",
    "\n",
    "'mode'  :'train',\n",
    "'model_path' :'./models',\n",
    "'sample_path' :'./samples',\n",
    "'mnist_path' :'./mnist',\n",
    "'svhn_path' :'./svhn',\n",
    "'log_step' : 10,\n",
    "'sample_step' : 500,\n",
    "\n",
    "'use_labels': False, \n",
    "'use_reconst_loss' : True, \n",
    "}\n",
    "\n",
    "config = dotdict(config1)\n",
    "old_loader, young_loader = get_loader(config)\n",
    "\n",
    "solver = Solver(config, old_loader, young_loader)\n",
    "solver.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.backends import cudnn\n",
    "from data_loader import get_loader\n",
    "from data_utils import FaceData\n",
    "from model import G12, G21\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "cudnn.benchmark = True \n",
    " \n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "config1 = {\n",
    "'image_size' : 200, \n",
    "'g_conv_dim' : 64, \n",
    "'d_conv_dim' : 64, \n",
    "'num_classes' : 10, \n",
    "'train_iters' : 40000,\n",
    "'batch_size' : 4,\n",
    "'num_workers' : 2,\n",
    "'lr' : 0.0002,\n",
    "'beta1' : 0.5,\n",
    "'beta2' : 0.999,\n",
    "\n",
    "'mode'  :'train',\n",
    "'model_path' :'./models',\n",
    "'sample_path' :'./samples',\n",
    "'mnist_path' :'./mnist',\n",
    "'svhn_path' :'./svhn',\n",
    "'log_step' : 10,\n",
    "'sample_step' : 500,\n",
    "\n",
    "'use_labels': False, \n",
    "'use_reconst_loss' : True, \n",
    "}\n",
    "\n",
    "config = dotdict(config1)\n",
    "\n",
    "old = FaceData(image_paths_file='LAG/train/train.txt', young=False)\n",
    "young = FaceData(image_paths_file='LAG/train/train.txt')\n",
    "\n",
    "g12 = G12(conv_dim=config.g_conv_dim)\n",
    "state_G12 = torch.load('models/g12-40000.pkl')\n",
    "g12.load_state_dict(state_G12)\n",
    "\n",
    "g21 = G21(conv_dim=config.g_conv_dim)\n",
    "state_G21 = torch.load('models/g21-40000.pkl')\n",
    "g21.load_state_dict(state_G21)\n",
    "\n",
    "\n",
    "num_example_imgs = 3\n",
    "plt.switch_backend('agg')\n",
    "plt.ion()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "#for i, (img, img_label) in enumerate(young[-num_example_imgs:]):\n",
    "\n",
    "img, _ = young[-1]\n",
    "inputs = img.unsqueeze(0)\n",
    "inputs = Variable(inputs)\n",
    "    \n",
    "outputs = g12.forward(inputs)\n",
    "reverse = g21.forward(outputs)    \n",
    "    \n",
    "pred = outputs.data.cpu()\n",
    "rev = reverse.data.cpu()\n",
    "\n",
    "#pred = pred.type(torch.LongTensor)    \n",
    "img, pred = img.numpy(), pred.numpy()\n",
    "rev = rev.numpy()\n",
    "pred = np.around(pred,decimals=2)\n",
    "pred = pred - np.min(pred)\n",
    "print((pred - np.min(pred)))\n",
    "\n",
    "rev = np.around(rev,decimals=2)\n",
    "rev = rev - np.min(rev)\n",
    "\n",
    "# img\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "print(img.transpose(1,2,0).shape)\n",
    "plt.imshow(img.transpose(1,2,0))\n",
    "    \n",
    "# pred\n",
    "plt.subplot(1, 2 ,2)\n",
    "plt.axis('off')\n",
    "#plt.imshow(pred.reshape(200,200,3))\n",
    "plt.imshow(rev.reshape(200,200,3))\n",
    "        \n",
    "plt.savefig('randomfig.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]]\n",
      "\n",
      " [[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]]\n",
      "\n",
      " [[ 1.          0.9999994   1.         ...,  0.99999887  1.          0.99992073]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          0.99999982  1.         ...,  0.99966192  1.          0.99998957]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99997514]\n",
      "  [ 1.          0.99999994  1.         ...,  0.99999827  1.          0.99996686]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]]]\n",
      "(200, 200, 3)\n",
      "[[[ 1.          1.          1.         ...,  1.          1.          0.99999982]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]]\n",
      "\n",
      " [[ 1.          1.          1.         ...,  1.          1.          0.99999982]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]]\n",
      "\n",
      " [[ 1.          0.99999958  1.         ...,  0.9999938   1.          0.99949604]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999976]\n",
      "  [ 1.          0.99999988  1.         ...,  0.9994604   1.          0.9998104 ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]]]\n",
      "(200, 200, 3)\n",
      "[[[ 1.          1.          1.         ...,  1.          1.          0.99999934]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]]\n",
      "\n",
      " [[ 1.          1.          1.         ...,  1.          1.          0.99999923]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]]\n",
      "\n",
      " [[ 1.          0.99999964  1.         ...,  0.99998438  1.          0.99877626]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999624]\n",
      "  [ 1.          0.99999988  1.         ...,  0.9991253   1.          0.99920517]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.9999873 ]\n",
      "  [ 1.          0.99999994  1.         ...,  0.99999857  1.          0.99997437]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          0.99999994]]]\n",
      "(200, 200, 3)\n",
      "[[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]]\n",
      "\n",
      " [[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]]\n",
      "\n",
      " [[ 1.          0.99999946  1.         ...,  0.99999994  1.          0.99994826]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          0.99999994  1.         ...,  0.99998009  1.          0.99999988]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          0.99999982  1.         ...,  0.99999982  1.          0.99999911]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]]]\n",
      "(200, 200, 3)\n",
      "[[[ 0.99999988  1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 0.99999982  1.          1.         ...,  1.          1.          1.        ]]\n",
      "\n",
      " [[ 0.99999988  1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 0.99999994  1.          1.         ...,  1.          1.          0.99999994]]\n",
      "\n",
      " [[ 0.99999988  0.99998426  1.         ...,  0.9999994   1.          0.99988103]\n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          0.99999899  1.         ...,  0.99978995  1.          0.99999607]\n",
      "  ..., \n",
      "  [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      "  [ 1.          0.9999997   1.         ...,  0.99999863  1.          0.99999893]\n",
      "  [ 0.99999994  1.          1.         ...,  1.          1.          1.        ]]]\n",
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.backends import cudnn\n",
    "from data_loader import get_loader\n",
    "from data_utils import FaceData\n",
    "from model import G12, G21\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "cudnn.benchmark = True \n",
    " \n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "config1 = {\n",
    "'image_size' : 200, \n",
    "'g_conv_dim' : 64, \n",
    "'d_conv_dim' : 64, \n",
    "'num_classes' : 10, \n",
    "'train_iters' : 40000,\n",
    "'batch_size' : 4,\n",
    "'num_workers' : 2,\n",
    "'lr' : 0.0002,\n",
    "'beta1' : 0.5,\n",
    "'beta2' : 0.999,\n",
    "\n",
    "'mode'  :'train',\n",
    "'model_path' :'./models',\n",
    "'sample_path' :'./samples',\n",
    "'mnist_path' :'./mnist',\n",
    "'svhn_path' :'./svhn',\n",
    "'log_step' : 10,\n",
    "'sample_step' : 500,\n",
    "\n",
    "'use_labels': False, \n",
    "'use_reconst_loss' : True, \n",
    "}\n",
    "\n",
    "config = dotdict(config1)\n",
    "\n",
    "old = FaceData(image_paths_file='LAG/train/train.txt', young=False)\n",
    "young = FaceData(image_paths_file='LAG/train/train.txt')\n",
    "\n",
    "g12 = G12(conv_dim=config.g_conv_dim)\n",
    "state_G12 = torch.load('models/g12-40000.pkl')\n",
    "g12.load_state_dict(state_G12)\n",
    "\n",
    "g21 = G21(conv_dim=config.g_conv_dim)\n",
    "state_G21 = torch.load('models/g21-40000.pkl')\n",
    "g21.load_state_dict(state_G21)\n",
    "\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "plt.ion()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "num_example_imgs = 5\n",
    "for i, (img, img_label) in enumerate(young[-num_example_imgs:]):\n",
    "\n",
    "    inputs = img.unsqueeze(0)\n",
    "    inputs = Variable(inputs)\n",
    "    \n",
    "    outputs = g12(inputs)\n",
    "    reverse = g21(outputs)    \n",
    "    \n",
    "    pred = outputs[0].data.cpu()\n",
    "    rev = reverse[0].data.cpu()\n",
    "\n",
    "    img, pred = img.numpy(), pred.numpy()\n",
    "    rev = rev.numpy()\n",
    "    print(pred)\n",
    "\n",
    "    #pred = np.around(pred,decimals=2)\n",
    "    pred = (pred - np.min(pred))/np.max(pred)*255\n",
    "    #print((pred - np.min(pred)))\n",
    "\n",
    "    rev = np.around(rev,decimals=2)\n",
    "    rev = rev - np.min(rev)\n",
    "\n",
    "    # img\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 1)\n",
    "    plt.axis('off')\n",
    "    print(img.transpose(1,2,0).shape)\n",
    "    plt.imshow(img.transpose(1,2,0))\n",
    "    \n",
    "    # pred\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 2)\n",
    "    plt.axis('off')\n",
    "    #plt.imshow(pred.reshape(200,200,3))\n",
    "    plt.imshow(pred.reshape(200,200,3))\n",
    "    \n",
    "    # rev\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 3)\n",
    "    plt.axis('off')\n",
    "    #plt.imshow(pred.reshape(200,200,3))\n",
    "    plt.imshow(rev.reshape(200,200,3))\n",
    "    \n",
    "    plt.savefig('randomfig.png')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
